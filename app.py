# =============================================================================
# app.py - í†µí•© ì§€í‘œ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ v7.0
#  - v5.0 (ì—‘ì…€ ê¸°ë°˜) + v6.0 (í¬ë¡¤ë§) í†µí•© ë²„ì „
#  - ì—‘ì…€ íˆìŠ¤í† ë¦¬ + ì›¹ í¬ë¡¤ë§(ë‹¹ì¼/ì „ì¼) ë³‘í•©
#  - í™˜ìœ¨ / REC / SMP / ìœ ê°€ / LNG / ê¸ˆë¦¬ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
# =============================================================================

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error
import requests
from bs4 import BeautifulSoup
import warnings

warnings.filterwarnings("ignore")

# =============================================================================
# ì„¤ì •
# =============================================================================

DATA_PATH = "data/ë°ì¼ë¦¬_í´ë¦¬í•‘_ìë£Œ.xlsm"

DATA_COLUMNS = [
    "ë‚ ì§œ",
    "ë‹¬ëŸ¬í™˜ìœ¨",
    "ì—”í™˜ìœ¨",
    "ìœ ë¡œí™˜ìœ¨",
    "ìœ„ì•ˆí™”í™˜ìœ¨",
    "ìœ¡ì§€ ê°€ê²©",
    "ìœ¡ì§€ ê±°ë˜ëŸ‰",
    "ì œì£¼ ê°€ê²©",
    "ì œì£¼ ê±°ë˜ëŸ‰",
    "ìœ¡ì§€ SMP",
    "ì œì£¼ SMP",
    "ë‘ë°”ì´ìœ ",
    "ë¸Œë ŒíŠ¸ìœ ",
    "WTI",
    "íƒ±í¬ë¡œë¦¬ìš©",
    "ì—°ë£Œì „ì§€ìš©",
    "ì½œê¸ˆë¦¬(1ì¼)",
    "CD (91ì¼)",
    "CP (91ì¼)",
    "êµ­ê³ ì±„ (3ë…„)",
    "êµ­ê³ ì±„ (5ë…„)",
    "êµ­ê³ ì±„ (10ë…„)",
    "ì‚°ê¸ˆì±„ (1ë…„)",
    "íšŒì‚¬ì±„ (3ë…„)(AA-)",
    "íšŒì‚¬ì±„ (3ë…„)(BBB-)",
    "IRS (3ë…„)",
    "IRS (5ë…„)",
    "IRS (10ë…„)",
    "CRS (1ë…„)",
    "CRS (3ë…„)",
]

INDICATORS = {
    "í™˜ìœ¨": {
        "icon": "ğŸ’±",
        "color": "#3498db",
        "columns": {
            "ë‹¬ëŸ¬í™˜ìœ¨": {"unit": "ì›", "format": "{:,.1f}"},
            "ì—”í™˜ìœ¨": {"unit": "ì›/100ì—”", "format": "{:,.2f}"},
            "ìœ ë¡œí™˜ìœ¨": {"unit": "ì›", "format": "{:,.2f}"},
            "ìœ„ì•ˆí™”í™˜ìœ¨": {"unit": "ì›", "format": "{:,.2f}"},
        },
    },
    "REC": {
        "icon": "ğŸ“—",
        "color": "#27ae60",
        "columns": {
            "ìœ¡ì§€ ê°€ê²©": {"unit": "ì›/REC", "format": "{:,.0f}"},
            "ìœ¡ì§€ ê±°ë˜ëŸ‰": {"unit": "REC", "format": "{:,.0f}"},
            "ì œì£¼ ê°€ê²©": {"unit": "ì›/REC", "format": "{:,.0f}"},
            "ì œì£¼ ê±°ë˜ëŸ‰": {"unit": "REC", "format": "{:,.0f}"},
        },
    },
    "SMP": {
        "icon": "âš¡",
        "color": "#f39c12",
        "columns": {
            "ìœ¡ì§€ SMP": {"unit": "ì›/kWh", "format": "{:,.2f}"},
            "ì œì£¼ SMP": {"unit": "ì›/kWh", "format": "{:,.2f}"},
        },
    },
    "ìœ ê°€": {
        "icon": "ğŸ›¢ï¸",
        "color": "#e74c3c",
        "columns": {
            "ë‘ë°”ì´ìœ ": {"unit": "$/ë°°ëŸ´", "format": "{:,.2f}"},
            "ë¸Œë ŒíŠ¸ìœ ": {"unit": "$/ë°°ëŸ´", "format": "{:,.2f}"},
            "WTI": {"unit": "$/ë°°ëŸ´", "format": "{:,.2f}"},
        },
    },
    "LNG": {
        "icon": "ğŸ”¥",
        "color": "#9b59b6",
        "columns": {
            "íƒ±í¬ë¡œë¦¬ìš©": {"unit": "ì›/MJ", "format": "{:,.4f}"},
            "ì—°ë£Œì „ì§€ìš©": {"unit": "ì›/MJ", "format": "{:,.4f}"},
        },
    },
    "ê¸ˆë¦¬": {
        "icon": "ğŸ“Š",
        "color": "#1abc9c",
        "columns": {
            "ì½œê¸ˆë¦¬(1ì¼)": {"unit": "%", "format": "{:,.3f}"},
            "CD (91ì¼)": {"unit": "%", "format": "{:,.2f}"},
            "CP (91ì¼)": {"unit": "%", "format": "{:,.2f}"},
            "êµ­ê³ ì±„ (3ë…„)": {"unit": "%", "format": "{:,.3f}"},
            "êµ­ê³ ì±„ (5ë…„)": {"unit": "%", "format": "{:,.3f}"},
            "êµ­ê³ ì±„ (10ë…„)": {"unit": "%", "format": "{:,.3f}"},
            "ì‚°ê¸ˆì±„ (1ë…„)": {"unit": "%", "format": "{:,.3f}"},
            "íšŒì‚¬ì±„ (3ë…„)(AA-)": {"unit": "%", "format": "{:,.3f}"},
            "íšŒì‚¬ì±„ (3ë…„)(BBB-)": {"unit": "%", "format": "{:,.3f}"},
        },
    },
    "ìŠ¤ì™‘": {
        "icon": "ğŸ”„",
        "color": "#34495e",
        "columns": {
            "IRS (3ë…„)": {"unit": "%", "format": "{:,.4f}"},
            "IRS (5ë…„)": {"unit": "%", "format": "{:,.4f}"},
            "IRS (10ë…„)": {"unit": "%", "format": "{:,.4f}"},
            "CRS (1ë…„)": {"unit": "%", "format": "{:,.2f}"},
            "CRS (3ë…„)": {"unit": "%", "format": "{:,.2f}"},
        },
    },
}

CHART_PERIODS = {"1ê°œì›”": 30, "3ê°œì›”": 90, "6ê°œì›”": 180, "1ë…„": 365, "ì „ì²´": None}

ALERT_THRESHOLDS = {
    "í™˜ìœ¨": 1.0,
    "REC": 3.0,
    "SMP": 5.0,
    "ìœ ê°€": 3.0,
    "LNG": 5.0,
    "ê¸ˆë¦¬": 0.1,
    "ìŠ¤ì™‘": 0.1,
}

KEY_INDICATORS = [
    "ë‹¬ëŸ¬í™˜ìœ¨",
    "ìœ ë¡œí™˜ìœ¨",
    "ìœ„ì•ˆí™”í™˜ìœ¨",
    "ìœ¡ì§€ SMP",
    "ì œì£¼ SMP",
    "ë‘ë°”ì´ìœ ",
    "ë¸Œë ŒíŠ¸ìœ ",
    "WTI",
    "êµ­ê³ ì±„ (3ë…„)",
    "êµ­ê³ ì±„ (5ë…„)",
    "êµ­ê³ ì±„ (10ë…„)",
    "IRS (3ë…„)",
    "IRS (5ë…„)",
]

# =============================================================================
# í˜ì´ì§€ ì„¤ì •
# =============================================================================

st.set_page_config(
    page_title="ğŸ“Š ì¹œí™˜ê²½Â·ì¸í”„ë¼ íˆ¬ì ëŒ€ì‹œë³´ë“œ v7.0",
    page_icon="ğŸŒ±",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =============================================================================
# CSS ìŠ¤íƒ€ì¼
# =============================================================================

st.markdown(
    """
<style>
    .main-header {
        background: linear-gradient(90deg, #0f3460 0%, #1a1a2e 100%);
        padding: 1.5rem 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        border: 1px solid #27ae60;
    }
    .main-header h1 { color: #ffffff; font-size: 2rem; margin: 0; }
    .main-header p { color: #aaaaaa; margin: 0.5rem 0 0 0; font-size: 0.9rem; }
    .metric-card {
        background: linear-gradient(145deg, #16213e 0%, #1a1a2e 100%);
        border-radius: 12px;
        padding: 1.2rem;
        border: 1px solid #0f3460;
        margin-bottom: 1rem;
    }
    .metric-card:hover { border-color: #27ae60; }
    .metric-title { color: #888888; font-size: 0.85rem; margin-bottom: 0.5rem; }
    .metric-value { color: #ffffff; font-size: 1.5rem; font-weight: 700; margin-bottom: 0.3rem; }
    .metric-change-up { color: #00d26a; font-size: 0.9rem; font-weight: 600; }
    .metric-change-down { color: #ff6b6b; font-size: 0.9rem; font-weight: 600; }
    .metric-change-neutral { color: #888888; font-size: 0.9rem; }
    .category-header {
        display: flex;
        align-items: center;
        gap: 0.5rem;
        padding: 0.8rem 1rem;
        background: linear-gradient(90deg, #0f3460 0%, transparent 100%);
        border-radius: 8px;
        margin: 1.5rem 0 1rem 0;
        border-left: 4px solid;
    }
    .category-header h3 { color: #ffffff; margin: 0; font-size: 1.1rem; }
    .alert-box {
        background: linear-gradient(90deg, rgba(233, 69, 96, 0.2) 0%, transparent 100%);
        border-left: 4px solid #e94560;
        padding: 1rem 1.5rem;
        border-radius: 0 8px 8px 0;
        margin-bottom: 1rem;
    }
    .alert-box h4 { color: #e94560; margin: 0 0 0.5rem 0; }
    .alert-item {
        background: rgba(233,69,96,0.1);
        padding: 0.8rem;
        border-radius: 8px;
        border: 1px solid;
        margin-bottom: 0.5rem;
    }
    .insight-box {
        background: linear-gradient(145deg, #1a3a5c 0%, #16213e 100%);
        border-radius: 12px;
        padding: 1.5rem;
        border: 1px solid #3498db;
        margin: 1rem 0;
    }
    .insight-box h4 { color: #3498db; margin: 0 0 0.8rem 0; }
    .insight-box p { color: #ffffff; margin: 0.3rem 0; line-height: 1.6; }
    .prediction-box {
        background: linear-gradient(145deg, #1a4a3c 0%, #16213e 100%);
        border-radius: 12px;
        padding: 1.5rem;
        border: 1px solid #27ae60;
        margin: 1rem 0;
    }
    .prediction-box h4 { color: #27ae60; margin: 0 0 0.8rem 0; }
    .signal-buy {
        background: linear-gradient(145deg, #1a4a3c 0%, #16213e 100%);
        border: 2px solid #00d26a;
        border-radius: 12px;
        padding: 1rem;
        text-align: center;
    }
    .signal-sell {
        background: linear-gradient(145deg, #4a1a1a 0%, #16213e 100%);
        border: 2px solid #ff6b6b;
        border-radius: 12px;
        padding: 1rem;
        text-align: center;
    }
    .signal-hold {
        background: linear-gradient(145deg, #3a3a1a 0%, #16213e 100%);
        border: 2px solid #f39c12;
        border-radius: 12px;
        padding: 1rem;
        text-align: center;
    }
    .summary-card {
        background: linear-gradient(145deg, #1a2a4a 0%, #16213e 100%);
        border-radius: 12px;
        padding: 1.5rem;
        border: 1px solid #3498db;
        margin: 0.5rem 0;
    }
    .manual-section {
        background: linear-gradient(145deg, #1a2a3a 0%, #16213e 100%);
        border-radius: 12px;
        padding: 1.5rem;
        border: 1px solid #3498db;
        margin: 1rem 0;
    }
    .manual-section h4 { color: #3498db; margin: 0 0 1rem 0; }
    .example-box {
        background: rgba(39, 174, 96, 0.1);
        border-left: 4px solid #27ae60;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
    }
    .tip-box {
        background: rgba(241, 196, 15, 0.1);
        border-left: 4px solid #f1c40f;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
    }
    .correlation-strong { color: #00d26a; font-weight: bold; }
    .correlation-moderate { color: #f39c12; font-weight: bold; }
    .correlation-weak { color: #888888; }
</style>
""",
    unsafe_allow_html=True,
)

# =============================================================================
# í¬ë¡¤ë§ í•¨ìˆ˜ë“¤ (ì‹¤ì œ HTML êµ¬ì¡°ì— ë§ê²Œ selectorëŠ” í•œ ë²ˆì”© í™•ì¸ í•„ìš”)
# =============================================================================


@st.cache_data(ttl=1800, show_spinner=False)
def fetch_fx_smbs(target_date):
    """
    í™˜ìœ¨ - ì„œìš¸ì™¸êµ­í™˜ì¤‘ê°œ (smbs.biz)
    URL: http://www.smbs.biz/ExRate/TodayExRate.jsp?tr_date=YYYYMMDD

    ë°˜í™˜ ì˜ˆì‹œ:
    {
      'ë‹¬ëŸ¬í™˜ìœ¨': 1473.5,
      'ì—”í™˜ìœ¨': 944.01,
      'ìœ ë¡œí™˜ìœ¨': 1704.99,
      'ìœ„ì•ˆí™”í™˜ìœ¨': 207.78
    }
    """
    base_url = "http://www.smbs.biz/ExRate/TodayExRate.jsp"
    params = {"tr_date": target_date.strftime("%Y%m%d")}
    fx = {}

    try:
        res = requests.get(base_url, params=params, timeout=10)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")

        table = soup.find("table")
        if not table:
            return fx

        for row in table.find_all("tr"):
            tds = row.find_all("td")
            if len(tds) < 2:
                continue

            name = tds[0].get_text(strip=True)
            val_txt = tds[1].get_text(strip=True).replace(",", "")

            try:
                value = float(val_txt)
            except ValueError:
                continue

            if "ë¯¸êµ­" in name or "USD" in name:
                fx["ë‹¬ëŸ¬í™˜ìœ¨"] = value
            elif "ì¼ë³¸" in name or "JPY" in name:
                fx["ì—”í™˜ìœ¨"] = value
            elif "ìœ ë¡œ" in name or "EUR" in name:
                fx["ìœ ë¡œí™˜ìœ¨"] = value
            elif "ì¤‘êµ­" in name or "CNY" in name:
                fx["ìœ„ì•ˆí™”í™˜ìœ¨"] = value

        return fx
    except Exception:
        return fx


@st.cache_data(ttl=3600, show_spinner=False)
def fetch_rec_smp_onerec():
    """
    REC + SMP - ì—ë„ˆì§€ê³µë‹¨ ONEREC í¬í„¸.

    ë°˜í™˜ í˜•ì‹:
    {
      'ìœ¡ì§€ ê°€ê²©': {'current': ..., 'prev': ...},
      'ìœ¡ì§€ ê±°ë˜ëŸ‰': {...},
      'ì œì£¼ ê°€ê²©': {...},
      'ì œì£¼ ê±°ë˜ëŸ‰': {...},
      'ìœ¡ì§€ SMP': {...},
      'ì œì£¼ SMP': {...}
    }

    â€» ì‹¤ì œ í…Œì´ë¸” í—¤ë”/ì—´ ìˆœì„œëŠ” ì‚¬ì´íŠ¸ HTMLì„ ë³´ê³  indexë¥¼ í•œë²ˆ ì¡°ì •í•´ì•¼ í•¨.
    """
    result = {}

    # --------------------------
    # REC
    # --------------------------
    try:
        rec_url = "https://onerec.kmos.kr/portal/rec/reportNewsList.do"
        params = {"key": "2335"}
        res = requests.get(rec_url, params=params, timeout=10)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")

        table = soup.find("table")
        if table:
            rows = table.find_all("tr")
            rows = [r for r in rows if r.find_all("td") or r.find_all("th")]
            if len(rows) >= 3:
                header = [th.get_text(strip=True) for th in rows[0].find_all(["th", "td"])]

                # ëŒ€ëµì ì¸ ìœ„ì¹˜ ì¶”ì • â€“ ì‹¤ì œ í—¤ë” í…ìŠ¤íŠ¸ ë³´ê³  ìˆ˜ì •
                idx_land_price = next(
                    (i for i, h in enumerate(header) if "ìœ¡ì§€" in h and ("ê°€ê²©" in h or "ì •ì‚°" in h)),
                    None,
                )
                idx_land_vol = next(
                    (i for i, h in enumerate(header) if "ìœ¡ì§€" in h and ("ê±°ë˜" in h or "ë¬¼ëŸ‰" in h)),
                    None,
                )
                idx_jeju_price = next(
                    (i for i, h in enumerate(header) if "ì œì£¼" in h and ("ê°€ê²©" in h or "ì •ì‚°" in h)),
                    None,
                )
                idx_jeju_vol = next(
                    (i for i, h in enumerate(header) if "ì œì£¼" in h and ("ê±°ë˜" in h or "ë¬¼ëŸ‰" in h)),
                    None,
                )

                def parse_row(row):
                    vals = []
                    for td in row.find_all("td"):
                        txt = (
                            td.get_text(strip=True)
                            .replace(",", "")
                            .replace("ì›", "")
                            .replace("REC", "")
                        )
                        try:
                            vals.append(float(txt))
                        except ValueError:
                            vals.append(None)
                    return vals

                data_rows = [r for r in rows[1:] if r.find_all("td")]
                if len(data_rows) >= 2:
                    today_vals = parse_row(data_rows[0])
                    yday_vals = parse_row(data_rows[1])

                    if idx_land_price is not None:
                        result["ìœ¡ì§€ ê°€ê²©"] = {
                            "current": today_vals[idx_land_price],
                            "prev": yday_vals[idx_land_price],
                        }
                    if idx_land_vol is not None:
                        result["ìœ¡ì§€ ê±°ë˜ëŸ‰"] = {
                            "current": today_vals[idx_land_vol],
                            "prev": yday_vals[idx_land_vol],
                        }
                    if idx_jeju_price is not None:
                        result["ì œì£¼ ê°€ê²©"] = {
                            "current": today_vals[idx_jeju_price],
                            "prev": yday_vals[idx_jeju_price],
                        }
                    if idx_jeju_vol is not None:
                        result["ì œì£¼ ê±°ë˜ëŸ‰"] = {
                            "current": today_vals[idx_jeju_vol],
                            "prev": yday_vals[idx_jeju_vol],
                        }
    except Exception:
        pass

    # --------------------------
    # SMP
    # --------------------------
    try:
        smp_url = "https://onerec.kmos.kr/portal/rec/selectRecSMPList.do"
        params = {"key": "1965"}
        res = requests.get(smp_url, params=params, timeout=10)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")

        table = soup.find("table")
        if table:
            rows = table.find_all("tr")
            rows = [r for r in rows if r.find_all("td") or r.find_all("th")]
            if len(rows) >= 3:
                header = [th.get_text(strip=True) for th in rows[0].find_all(["th", "td"])]

                idx_main = next(
                    (i for i, h in enumerate(header) if "ìœ¡ì§€" in h and "SMP" in h),
                    None,
                )
                idx_jeju = next(
                    (i for i, h in enumerate(header) if "ì œì£¼" in h and "SMP" in h),
                    None,
                )

                def parse_row(row):
                    vals = []
                    for td in row.find_all("td"):
                        txt = td.get_text(strip=True).replace(",", "")
                        try:
                            vals.append(float(txt))
                        except ValueError:
                            vals.append(None)
                    return vals

                data_rows = [r for r in rows[1:] if r.find_all("td")]
                if len(data_rows) >= 2:
                    today_vals = parse_row(data_rows[0])
                    yday_vals = parse_row(data_rows[1])

                    if idx_main is not None:
                        result["ìœ¡ì§€ SMP"] = {
                            "current": today_vals[idx_main],
                            "prev": yday_vals[idx_main],
                        }
                    if idx_jeju is not None:
                        result["ì œì£¼ SMP"] = {
                            "current": today_vals[idx_jeju],
                            "prev": yday_vals[idx_jeju],
                        }
    except Exception:
        pass

    return result


@st.cache_data(ttl=3600, show_spinner=False)
def fetch_oil_petronet():
    """
    êµ­ì œìœ ê°€ - Petronet
    URL: https://www.petronet.co.kr/v4/sub.jsp?fmuId=KDFQSTAT&smuId=KDFQ01

    ë°˜í™˜ ì˜ˆì‹œ:
    {
      'ë‘ë°”ì´ìœ ': {'current': ..., 'prev': ...},
      'ë¸Œë ŒíŠ¸ìœ ': {'current': ..., 'prev': ...},
      'WTI': {'current': ..., 'prev': ...}
    }
    """
    url = "https://www.petronet.co.kr/v4/sub.jsp"
    params = {"fmuId": "KDFQSTAT", "smuId": "KDFQ01"}
    result = {}

    try:
        res = requests.get(url, params=params, timeout=10)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")

        table = soup.find("table")
        if not table:
            return result

        rows = [r for r in table.find_all("tr") if r.find_all("td")]
        if len(rows) < 2:
            return result

        # ë§ˆì§€ë§‰ ë‘ í–‰ì„ ì „ì¼/ë‹¹ì¼ë¡œ ê°€ì • (ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ í•„ìš”ì‹œ ì¡°ì •)
        prev_row = rows[-2]
        curr_row = rows[-1]

        def parse_row(row):
            vals = []
            for td in row.find_all("td"):
                txt = td.get_text(strip=True).replace(",", "")
                try:
                    vals.append(float(txt))
                except ValueError:
                    vals.append(None)
            return vals

        prev_vals = parse_row(prev_row)
        curr_vals = parse_row(curr_row)

        # [ë‚ ì§œ, ë‘ë°”ì´, ë¸Œë ŒíŠ¸, WTI] ìˆœì´ë¼ê³  ê°€ì •
        if len(curr_vals) >= 4 and len(prev_vals) >= 4:
            result["ë‘ë°”ì´ìœ "] = {"current": curr_vals[1], "prev": prev_vals[1]}
            result["ë¸Œë ŒíŠ¸ìœ "] = {"current": curr_vals[2], "prev": prev_vals[2]}
            result["WTI"] = {"current": curr_vals[3], "prev": prev_vals[3]}

    except Exception:
        pass

    return result


@st.cache_data(ttl=3600, show_spinner=False)
def fetch_lng_kogas():
    """
    LNG ê°€ê²© - í•œêµ­ê°€ìŠ¤ê³µì‚¬
    URL: https://www.kogas.or.kr/site/koGas/1040401000000

    ë°˜í™˜ ì˜ˆì‹œ:
    {
      'íƒ±í¬ë¡œë¦¬ìš©': {'current': ..., 'prev': ...},
      'ì—°ë£Œì „ì§€ìš©': {'current': ..., 'prev': ...}
    }
    """
    url = "https://www.kogas.or.kr/site/koGas/1040401000000"
    result = {}

    try:
        res = requests.get(url, timeout=10)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")

        table = soup.find("table")
        if not table:
            return result

        rows = [r for r in table.find_all("tr") if r.find_all("td")]
        if len(rows) < 2:
            return result

        curr_row = rows[0]
        prev_row = rows[1]

        header_cells = [th.get_text(strip=True) for th in table.find_all("th")]
        idx_tanker = next(
            (i for i, h in enumerate(header_cells) if "íƒ±í¬ë¡œë¦¬" in h),
            None,
        )
        idx_fuel = next(
            (i for i, h in enumerate(header_cells) if "ì—°ë£Œì „ì§€" in h),
            None,
        )

        def parse_row(row):
            vals = []
            for td in row.find_all("td"):
                txt = (
                    td.get_text(strip=True)
                    .replace(",", "")
                    .replace("ì›", "")
                    .replace("MJ", "")
                )
                try:
                    vals.append(float(txt))
                except ValueError:
                    vals.append(None)
            return vals

        curr_vals = parse_row(curr_row)
        prev_vals = parse_row(prev_row)

        if idx_tanker is not None and idx_tanker < len(curr_vals):
            result["íƒ±í¬ë¡œë¦¬ìš©"] = {
                "current": curr_vals[idx_tanker],
                "prev": prev_vals[idx_tanker]
                if idx_tanker < len(prev_vals)
                else curr_vals[idx_tanker],
            }
        if idx_fuel is not None and idx_fuel < len(curr_vals):
            result["ì—°ë£Œì „ì§€ìš©"] = {
                "current": curr_vals[idx_fuel],
                "prev": prev_vals[idx_fuel]
                if idx_fuel < len(prev_vals)
                else curr_vals[idx_fuel],
            }
    except Exception:
        pass

    return result


def ecos_request(stat_code, start_date, end_date, item_code=None):
    """
    í•œêµ­ì€í–‰ ECOS API í…œí”Œë¦¿.
    ì‹¤ì œ stat_code / item_codeëŠ” ECOS ê°œë°œìì„¼í„°ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì½”ë“œë¡œ êµì²´ í•„ìš”.
    """
    api_key = st.secrets.get("ECOS_API_KEY", "")
    if not api_key:
        return []

    base_url = (
        f"https://ecos.bok.or.kr/api/StatisticSearch/{api_key}/json/kr/1/10/"
        f"{stat_code}/DD/{start_date}/{end_date}"
    )
    if item_code:
        base_url += f"/{item_code}"

    try:
        res = requests.get(base_url, timeout=10)
        data = res.json()
        return data.get("StatisticSearch", {}).get("row", [])
    except Exception:
        return []


@st.cache_data(ttl=3600, show_spinner=False)
def fetch_rates_ecos(today, yesterday):
    """
    ECOSì—ì„œ ì½œê¸ˆë¦¬, êµ­ê³ ì±„3ë…„ ë“± ê¸ˆë¦¬ë¥¼ ê°€ì ¸ì˜¤ëŠ” í…œí”Œë¦¿.

    ì‹¤ì œ stat_code / item_codeëŠ” ì—°ì¤€ë‹˜ì´ ì“°ëŠ” ì‹œë¦¬ì¦ˆë¡œ êµì²´í•´ì•¼ í•¨.
    í˜„ì¬ëŠ” êµ¬ì¡°ë§Œ ì¡ì•„ë‘” ìƒíƒœ.
    """
    result = {}

    today_str = today.strftime("%Y%m%d")
    yday_str = yesterday.strftime("%Y%m%d")

    # ì˜ˆì‹œ 1) ì½œê¸ˆë¦¬(1ì¼) - (ì½”ë“œ ì˜ˆì‹œëŠ” placeholder)
    call_rows = ecos_request("722Y001", yday_str, today_str, item_code="0100000")
    if call_rows:
        call_rows = sorted(call_rows, key=lambda r: r.get("TIME", ""))
        prev_val = float(call_rows[0]["DATA_VALUE"])
        curr_val = float(call_rows[-1]["DATA_VALUE"])
        result["ì½œê¸ˆë¦¬(1ì¼)"] = {"current": curr_val, "prev": prev_val}

    # ì˜ˆì‹œ 2) êµ­ê³ ì±„(3ë…„) - placeholder
    t3_rows = ecos_request("733Y001", yday_str, today_str, item_code="BBK3Y")
    if t3_rows:
        t3_rows = sorted(t3_rows, key=lambda r: r.get("TIME", ""))
        prev_val = float(t3_rows[0]["DATA_VALUE"])
        curr_val = float(t3_rows[-1]["DATA_VALUE"])
        result["êµ­ê³ ì±„ (3ë…„)"] = {"current": curr_val, "prev": prev_val}

    # ë‚˜ë¨¸ì§€ CD, CP, êµ­ê³ ì±„5/10ë…„, íšŒì‚¬ì±„ AA-/BBB- ë“±ë„ ìœ„ íŒ¨í„´ìœ¼ë¡œ ì¶”ê°€ ê°€ëŠ¥
    return result


@st.cache_data(ttl=1800, show_spinner=False)
def fetch_realtime_data_with_history():
    """
    í¬ë¡¤ë§ì„ í†µí•´ 'ì˜¤ëŠ˜/ì „ì¼' ë°ì´í„°ë¥¼ ëª¨ë‘ ê°€ì ¸ì™€ì„œ í†µí•© mapìœ¼ë¡œ ë°˜í™˜.

    ë°˜í™˜ ì˜ˆì‹œ:
    {
      'ë‹¬ëŸ¬í™˜ìœ¨': {'current': 1473.5, 'prev': 1462.7},
      'ìœ¡ì§€ SMP': {'current': 110.5, 'prev': 108.2},
      ...
    }
    """
    today = datetime.today().date()
    yesterday = today - timedelta(days=1)

    data = {}

    # í™˜ìœ¨
    fx_today = fetch_fx_smbs(today)
    fx_yday = fetch_fx_smbs(yesterday)
    for name in ["ë‹¬ëŸ¬í™˜ìœ¨", "ì—”í™˜ìœ¨", "ìœ ë¡œí™˜ìœ¨", "ìœ„ì•ˆí™”í™˜ìœ¨"]:
        if name in fx_today and name in fx_yday:
            data[name] = {"current": fx_today[name], "prev": fx_yday[name]}

    # REC / SMP
    rec_smp = fetch_rec_smp_onerec()
    for k, v in rec_smp.items():
        data[k] = v

    # ìœ ê°€
    oil = fetch_oil_petronet()
    for k, v in oil.items():
        data[k] = v

    # LNG
    lng = fetch_lng_kogas()
    for k, v in lng.items():
        data[k] = v

    # ê¸ˆë¦¬ (ECOS)
    rates = fetch_rates_ecos(today, yesterday)
    for k, v in rates.items():
        data[k] = v

    return data


# =============================================================================
# ë°ì´í„° ë¡œë”© (ì—‘ì…€ íˆìŠ¤í† ë¦¬ + í¬ë¡¤ë§ ë³‘í•©)
# =============================================================================


@st.cache_data(ttl=600)
def load_data():
    """
    1) DATA_PATH ì—‘ì…€ íŒŒì¼ì—ì„œ íˆìŠ¤í† ë¦¬ ë¡œë“œ (ê°€ëŠ¥í•˜ë©´)
    2) fetch_realtime_data_with_history()ë¡œ ì˜¤ëŠ˜/ì „ì¼ ë°ì´í„° ë¡œë“œ
    3) íˆìŠ¤í† ë¦¬ì— ì˜¤ëŠ˜/ì „ì¼ rowë¥¼ ë®ì–´ì¨ì„œ ìµœì¢… df ë°˜í™˜
    """
    base_df = None
    try:
        base_df = pd.read_excel(
            DATA_PATH,
            sheet_name="Data",
            skiprows=4,
            usecols="B:AE",
            engine="openpyxl",
        )
        base_df.columns = DATA_COLUMNS
        base_df["ë‚ ì§œ"] = pd.to_datetime(base_df["ë‚ ì§œ"], errors="coerce")
        base_df = base_df.dropna(subset=["ë‚ ì§œ"])
        base_df = base_df.sort_values("ë‚ ì§œ").reset_index(drop=True)

        numeric_cols = [c for c in base_df.columns if c != "ë‚ ì§œ"]
        for col in numeric_cols:
            base_df[col] = pd.to_numeric(base_df[col], errors="coerce")
    except Exception:
        base_df = None

    realtime_map = fetch_realtime_data_with_history()

    if not realtime_map and base_df is None:
        st.error("âŒ ì—‘ì…€ íŒŒì¼ë„ ì—†ê³ , ì‹¤ì‹œê°„ ë°ì´í„°ë„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    today = datetime.today().date()
    yesterday = today - timedelta(days=1)

    # ê¸°ë³¸ row í…œí”Œë¦¿
    if base_df is not None and len(base_df) > 0:
        df_hist = base_df.copy()
        df_hist["date_only"] = df_hist["ë‚ ì§œ"].dt.date
        df_hist = df_hist[df_hist["date_only"] < yesterday].drop(columns="date_only")
        if len(df_hist) > 0:
            base_row = df_hist.iloc[-1].copy()
        else:
            base_row = pd.Series({col: np.nan for col in DATA_COLUMNS})
    else:
        df_hist = None
        base_row = pd.Series({col: np.nan for col in DATA_COLUMNS})

    def build_row(date_obj, key):
        row = base_row.copy()
        row["ë‚ ì§œ"] = pd.Timestamp(date_obj)
        for col in DATA_COLUMNS:
            if col == "ë‚ ì§œ":
                continue
            if col in realtime_map and realtime_map[col].get(key) is not None:
                row[col] = realtime_map[col][key]
        return row

    new_rows = []
    if realtime_map:
        new_rows.append(build_row(yesterday, "prev"))
        new_rows.append(build_row(today, "current"))

    if df_hist is not None:
        df_new = pd.concat([df_hist, pd.DataFrame(new_rows)], ignore_index=True)
    else:
        df_new = pd.DataFrame(new_rows)

    df_new = df_new.dropna(subset=["ë‚ ì§œ"])
    df_new = df_new.sort_values("ë‚ ì§œ")
    df_new = df_new.drop_duplicates(subset=["ë‚ ì§œ"], keep="last").reset_index(drop=True)

    # í•µì‹¬ ì§€í‘œê°€ ì „ë¶€ NaNì¸ í–‰ ì œê±°
    key_cols = ["ë‹¬ëŸ¬í™˜ìœ¨", "ìœ¡ì§€ SMP", "ë‘ë°”ì´ìœ "]
    existing_keys = [c for c in key_cols if c in df_new.columns]
    if existing_keys:
        mask = df_new[existing_keys].notna().any(axis=1)
        df_new = df_new[mask].reset_index(drop=True)

    return df_new


# =============================================================================
# LNG ì›”ë³„ ì²˜ë¦¬ (v5 ë¡œì§ ìœ ì§€)
# =============================================================================


def get_latest_lng_data(df):
    lng_cols = ["íƒ±í¬ë¡œë¦¬ìš©", "ì—°ë£Œì „ì§€ìš©"]
    result = {}

    for col in lng_cols:
        if col not in df.columns:
            result[col] = {
                "value": None,
                "previous": None,
                "change": None,
                "date": None,
                "prev_month": None,
                "curr_month": None,
            }
            continue

        valid_data = df[df[col].notna()][["ë‚ ì§œ", col]].copy()
        if len(valid_data) > 0:
            valid_data["ë…„ì›”"] = valid_data["ë‚ ì§œ"].dt.to_period("M")
            monthly_data = valid_data.groupby("ë…„ì›”").last().reset_index()

            if len(monthly_data) >= 2:
                latest = monthly_data.iloc[-1]
                prev = monthly_data.iloc[-2]
                change = latest[col] - prev[col]

                result[col] = {
                    "value": latest[col],
                    "previous": prev[col],
                    "change": change,
                    "date": latest["ë‚ ì§œ"],
                    "prev_month": str(prev["ë…„ì›”"]),
                    "curr_month": str(latest["ë…„ì›”"]),
                }
            elif len(monthly_data) == 1:
                latest = monthly_data.iloc[-1]
                result[col] = {
                    "value": latest[col],
                    "previous": None,
                    "change": None,
                    "date": latest["ë‚ ì§œ"],
                    "prev_month": None,
                    "curr_month": str(latest["ë…„ì›”"]),
                }
            else:
                result[col] = {
                    "value": None,
                    "previous": None,
                    "change": None,
                    "date": None,
                    "prev_month": None,
                    "curr_month": None,
                }
        else:
            result[col] = {
                "value": None,
                "previous": None,
                "change": None,
                "date": None,
                "prev_month": None,
                "curr_month": None,
            }
    return result


# =============================================================================
# ìš”ì•½/ì•Œë¦¼ ê´€ë ¨ í•¨ìˆ˜
# =============================================================================


def get_summary(df):
    if df is None or len(df) < 2:
        return {}

    latest = df.iloc[-1]
    previous = df.iloc[-2]
    summary = {}
    lng_data = get_latest_lng_data(df)

    for category, info in INDICATORS.items():
        is_rate = category in ["ê¸ˆë¦¬", "ìŠ¤ì™‘"]
        summary[category] = {
            "icon": info["icon"],
            "color": info["color"],
            "indicators": {},
        }

        for col_name, col_info in info["columns"].items():
            if category == "LNG" and col_name in lng_data:
                lng_info = lng_data[col_name]
                current = lng_info["value"]
                prev = lng_info["previous"]
                change = lng_info["change"]

                if change is not None:
                    direction = "up" if change > 0 else ("down" if change < 0 else "neutral")
                    change_pct = change
                else:
                    direction = "neutral"
                    change_pct = None

                if lng_info.get("prev_month") and lng_info.get("curr_month"):
                    prev_m = (
                        lng_info["prev_month"].split("-")[1]
                        if "-" in str(lng_info["prev_month"])
                        else ""
                    )
                    curr_m = (
                        lng_info["curr_month"].split("-")[1]
                        if "-" in str(lng_info["curr_month"])
                        else ""
                    )
                    note = f"({prev_m}ì›”â†’{curr_m}ì›”)"
                else:
                    note = ""

                summary[category]["indicators"][col_name] = {
                    "value": current,
                    "previous": prev,
                    "change": change,
                    "change_pct": change_pct,
                    "direction": direction,
                    "unit": col_info["unit"],
                    "format": col_info["format"],
                    "note": note,
                    "is_lng": True,
                }
            else:
                current = latest.get(col_name)
                prev = previous.get(col_name)

                if pd.notna(current) and pd.notna(prev) and prev != 0:
                    change = current - prev
                    change_pct = (change / prev) * 100 if not is_rate else change * 100
                    direction = "up" if change > 0 else ("down" if change < 0 else "neutral")
                else:
                    change, change_pct, direction = None, None, "neutral"

                summary[category]["indicators"][col_name] = {
                    "value": current,
                    "previous": prev,
                    "change": change,
                    "change_pct": change_pct,
                    "direction": direction,
                    "unit": col_info["unit"],
                    "format": col_info["format"],
                    "note": "",
                }
    return summary


def check_alerts(summary):
    alerts = []
    for category, data in summary.items():
        threshold = ALERT_THRESHOLDS.get(category, 5.0)
        is_rate = category in ["ê¸ˆë¦¬", "ìŠ¤ì™‘"]

        for col_name, ind in data["indicators"].items():
            if ind["change_pct"] is None:
                continue

            check_val = abs(ind["change"]) * 100 if is_rate else abs(ind["change_pct"])
            threshold_val = threshold * 100 if is_rate else threshold

            if check_val >= threshold_val:
                alerts.append(
                    {
                        "category": category,
                        "indicator": col_name,
                        "change_pct": ind["change_pct"],
                        "direction": ind["direction"],
                        "icon": data["icon"],
                        "current": ind.get("value"),
                        "previous": ind.get("previous"),
                        "fmt": ind.get("format", "{:,.2f}"),
                        "unit": ind.get("unit", ""),
                    }
                )
    return alerts


def format_value(value, fmt, unit=""):
    if pd.isna(value) or value is None:
        return "N/A"
    try:
        return f"{fmt.format(value)} {unit}"
    except Exception:
        return str(value)


def get_change_html(change, change_pct, direction, is_rate=False, is_lng=False):
    if change is None:
        return '<span class="metric-change-neutral">-</span>'

    arrow = "â–²" if direction == "up" else ("â–¼" if direction == "down" else "â€•")
    css = (
        "metric-change-up"
        if direction == "up"
        else ("metric-change-down" if direction == "down" else "metric-change-neutral")
    )

    if is_rate:
        return f'<span class="{css}">{arrow} {abs(change)*100:.1f}bp</span>'
    elif is_lng:
        return f'<span class="{css}">{arrow} {abs(change):.2f}</span>'
    return f'<span class="{css}">{arrow} {abs(change_pct):.2f}%</span>'


def create_metric_card(title, value, change_html, note=""):
    note_html = f'<div style="color: #666; font-size: 0.75rem;">{note}</div>' if note else ""
    return f"""
    <div class="metric-card">
        <div class="metric-title">{title}</div>
        <div class="metric-value">{value}</div>
        <div>{change_html}</div>
        {note_html}
    </div>
    """


# =============================================================================
# ìƒê´€ê´€ê³„/íšŒê·€ë¶„ì„ í•¨ìˆ˜
# =============================================================================


def calculate_correlation_matrix(df, columns, days=365):
    if days:
        cutoff = df["ë‚ ì§œ"].max() - timedelta(days=days)
        df_filtered = df[df["ë‚ ì§œ"] >= cutoff]
    else:
        df_filtered = df
    return df_filtered[columns].dropna().corr()


def calculate_lagged_correlation(df, leading_col, lagging_col, max_lag=30):
    results = []
    df_clean = df[["ë‚ ì§œ", leading_col, lagging_col]].dropna()

    for lag in range(0, max_lag + 1):
        if lag == 0:
            corr, p_value = stats.pearsonr(df_clean[leading_col], df_clean[lagging_col])
        else:
            leading_shifted = df_clean[leading_col].iloc[:-lag].values
            lagging_current = df_clean[lagging_col].iloc[lag:].values
            if len(leading_shifted) > 10:
                corr, p_value = stats.pearsonr(leading_shifted, lagging_current)
            else:
                corr, p_value = np.nan, np.nan
        results.append(
            {
                "lag": lag,
                "correlation": corr,
                "p_value": p_value,
                "significant": p_value < 0.05 if not np.isnan(p_value) else False,
            }
        )
    return pd.DataFrame(results)


def find_optimal_lag(lag_df):
    valid_df = lag_df.dropna()
    if len(valid_df) == 0:
        return None
    idx = valid_df["correlation"].abs().idxmax()
    return valid_df.loc[idx]


def interpret_correlation(corr):
    abs_corr = abs(corr)
    if abs_corr >= 0.7:
        return "ê°•í•œ", "ì–‘ì˜" if corr > 0 else "ìŒì˜", "correlation-strong"
    elif abs_corr >= 0.4:
        return "ì¤‘ê°„", "ì–‘ì˜" if corr > 0 else "ìŒì˜", "correlation-moderate"
    return "ì•½í•œ", "ì–‘ì˜" if corr > 0 else "ìŒì˜", "correlation-weak"


def build_regression_model(df, target_col, feature_cols, train_days=365):
    cutoff = (
        df["ë‚ ì§œ"].max() - timedelta(days=train_days)
        if train_days
        else df["ë‚ ì§œ"].min()
    )
    df_train = df[df["ë‚ ì§œ"] >= cutoff].copy()

    cols_needed = [target_col] + feature_cols
    df_clean = df_train[cols_needed].dropna()

    if len(df_clean) < 30:
        return None, None, None, "ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"

    X = df_clean[feature_cols].values
    y = df_clean[target_col].values

    scaler_X = StandardScaler()
    scaler_y = StandardScaler()

    X_scaled = scaler_X.fit_transform(X)
    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).ravel()

    model = LinearRegression()
    model.fit(X_scaled, y_scaled)

    y_pred_scaled = model.predict(X_scaled)
    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()

    r2 = r2_score(y, y_pred)
    mae = mean_absolute_error(y, y_pred)

    coef_info = [
        {
            "feature": col,
            "coefficient": model.coef_[i],
            "importance": abs(model.coef_[i]),
        }
        for i, col in enumerate(feature_cols)
    ]
    coef_df = pd.DataFrame(coef_info).sort_values("importance", ascending=False)

    return (
        {
            "model": model,
            "scaler_X": scaler_X,
            "scaler_y": scaler_y,
            "r2": r2,
            "mae": mae,
            "coefficients": coef_df,
            "y_actual": y,
            "y_pred": y_pred,
            "dates": df_train[df_train[target_col].notna()]["ë‚ ì§œ"]
            .iloc[-len(y) :]
            .values,
        },
        X,
        y,
        None,
    )


def predict_future(model_info, df, feature_cols):
    if model_info is None:
        return None
    latest = df[feature_cols].dropna().iloc[-1].values.reshape(1, -1)
    latest_scaled = model_info["scaler_X"].transform(latest)
    pred_scaled = model_info["model"].predict(latest_scaled)
    return model_info["scaler_y"].inverse_transform(pred_scaled.reshape(-1, 1)).ravel()[
        0
    ]


# =============================================================================
# ì‹ ì¬ìƒì—ë„ˆì§€ ìˆ˜ìµì„± ì‹œë®¬ë ˆì´í„°
# =============================================================================


def calculate_renewable_revenue(smp, rec_price, capacity_mw, cf=0.15, rec_weight=1.0):
    annual_generation = capacity_mw * 1000 * 24 * 365 * cf / 1000
    smp_revenue = annual_generation * smp * 1000
    rec_count = annual_generation * rec_weight
    rec_revenue = rec_count * rec_price
    total_revenue = smp_revenue + rec_revenue

    return {
        "annual_generation_mwh": annual_generation,
        "smp_revenue": smp_revenue,
        "rec_revenue": rec_revenue,
        "total_revenue": total_revenue,
        "revenue_per_mw": total_revenue / capacity_mw if capacity_mw > 0 else 0,
    }


# =============================================================================
# íˆ¬ì ì‹œê·¸ë„ / ì‹œì¥ ìš”ì•½
# =============================================================================


def generate_investment_signals(df, days=30):
    signals = []
    if len(df) < days:
        return signals

    latest = df.iloc[-1]
    recent = df.tail(days)

    # SMP
    smp_current = latest.get("ìœ¡ì§€ SMP")
    smp_avg = recent["ìœ¡ì§€ SMP"].mean()
    smp_std = recent["ìœ¡ì§€ SMP"].std()

    if pd.notna(smp_current) and pd.notna(smp_avg):
        if smp_current < smp_avg - smp_std:
            signals.append(
                {
                    "category": "ì‹ ì¬ìƒì—ë„ˆì§€",
                    "indicator": "SMP",
                    "signal": "BUY",
                    "reason": f"SMPê°€ 30ì¼ í‰ê·  ëŒ€ë¹„ ì €ì  (í˜„ì¬: {smp_current:.1f}, í‰ê· : {smp_avg:.1f})",
                    "strength": "STRONG"
                    if smp_current < smp_avg - 2 * smp_std
                    else "MODERATE",
                }
            )
        elif smp_current > smp_avg + smp_std:
            signals.append(
                {
                    "category": "ì‹ ì¬ìƒì—ë„ˆì§€",
                    "indicator": "SMP",
                    "signal": "SELL",
                    "reason": f"SMPê°€ 30ì¼ í‰ê·  ëŒ€ë¹„ ê³ ì  (í˜„ì¬: {smp_current:.1f}, í‰ê· : {smp_avg:.1f})",
                    "strength": "STRONG"
                    if smp_current > smp_avg + 2 * smp_std
                    else "MODERATE",
                }
            )

    # REC
    rec_current = latest.get("ìœ¡ì§€ ê°€ê²©")
    rec_avg = recent["ìœ¡ì§€ ê°€ê²©"].mean()
    rec_std = recent["ìœ¡ì§€ ê°€ê²©"].std()

    if pd.notna(rec_current) and pd.notna(rec_avg) and rec_std > 0:
        if rec_current < rec_avg - rec_std:
            signals.append(
                {
                    "category": "ì‹ ì¬ìƒì—ë„ˆì§€",
                    "indicator": "REC",
                    "signal": "BUY",
                    "reason": f"REC ê°€ê²© ì €ì  ë§¤ìˆ˜ ê¸°íšŒ (í˜„ì¬: {rec_current:,.0f}, í‰ê· : {rec_avg:,.0f})",
                    "strength": "STRONG"
                    if rec_current < rec_avg - 2 * rec_std
                    else "MODERATE",
                }
            )

    # ê¸ˆë¦¬
    rate_current = latest.get("êµ­ê³ ì±„ (3ë…„)")
    rate_avg = recent["êµ­ê³ ì±„ (3ë…„)"].mean()

    if pd.notna(rate_current) and pd.notna(rate_avg):
        if rate_current > rate_avg + 0.1:
            signals.append(
                {
                    "category": "ì¸í”„ë¼",
                    "indicator": "ê¸ˆë¦¬",
                    "signal": "HOLD",
                    "reason": f"ê¸ˆë¦¬ ìƒìŠ¹ ì¤‘ - ì‹ ê·œ ì°¨ì… ì£¼ì˜ (í˜„ì¬: {rate_current:.2f}%, í‰ê· : {rate_avg:.2f}%)",
                    "strength": "MODERATE",
                }
            )
        elif rate_current < rate_avg - 0.1:
            signals.append(
                {
                    "category": "ì¸í”„ë¼",
                    "indicator": "ê¸ˆë¦¬",
                    "signal": "BUY",
                    "reason": f"ê¸ˆë¦¬ í•˜ë½ - ì°¨ì… ì ê¸° (í˜„ì¬: {rate_current:.2f}%, í‰ê· : {rate_avg:.2f}%)",
                    "strength": "MODERATE",
                }
            )

    # í™˜ìœ¨
    fx_current = latest.get("ë‹¬ëŸ¬í™˜ìœ¨")
    fx_avg = recent["ë‹¬ëŸ¬í™˜ìœ¨"].mean()
    fx_std = recent["ë‹¬ëŸ¬í™˜ìœ¨"].std()

    if pd.notna(fx_current) and pd.notna(fx_avg) and fx_std > 0:
        if fx_current > fx_avg + fx_std:
            signals.append(
                {
                    "category": "í•´ì™¸íˆ¬ì",
                    "indicator": "í™˜ìœ¨",
                    "signal": "HOLD",
                    "reason": f"ì›í™” ì•½ì„¸ - í•´ì™¸ ì‹ ê·œ íˆ¬ì ì£¼ì˜ (í˜„ì¬: {fx_current:,.0f}ì›)",
                    "strength": "MODERATE",
                }
            )
        elif fx_current < fx_avg - fx_std:
            signals.append(
                {
                    "category": "í•´ì™¸íˆ¬ì",
                    "indicator": "í™˜ìœ¨",
                    "signal": "BUY",
                    "reason": f"ì›í™” ê°•ì„¸ - í•´ì™¸ íˆ¬ì ì ê¸° (í˜„ì¬: {fx_current:,.0f}ì›)",
                    "strength": "MODERATE",
                }
            )

    return signals


def generate_market_summary(df, days=7):
    if len(df) < days:
        return None

    recent = df.tail(days)
    prev_period = df.iloc[-(days * 2) : -days] if len(df) >= days * 2 else df.head(days)

    summary = {}
    indicators = {
        "ë‹¬ëŸ¬í™˜ìœ¨": {"name": "ë‹¬ëŸ¬/ì› í™˜ìœ¨", "unit": "ì›", "format": "{:,.1f}"},
        "ìœ¡ì§€ SMP": {"name": "SMP (ìœ¡ì§€)", "unit": "ì›/kWh", "format": "{:,.1f}"},
        "ìœ¡ì§€ ê°€ê²©": {"name": "REC ê°€ê²©", "unit": "ì›", "format": "{:,.0f}"},
        "ë‘ë°”ì´ìœ ": {"name": "ë‘ë°”ì´ìœ ", "unit": "$/ë°°ëŸ´", "format": "{:,.1f}"},
        "êµ­ê³ ì±„ (3ë…„)": {"name": "êµ­ê³ ì±„ 3ë…„", "unit": "%", "format": "{:,.2f}"},
    }

    for col, info in indicators.items():
        if col not in df.columns:
            continue
        current_avg = recent[col].mean()
        prev_avg = prev_period[col].mean()
        current_last = recent[col].iloc[-1]

        if pd.notna(current_avg) and pd.notna(prev_avg) and prev_avg != 0:
            change_pct = (current_avg - prev_avg) / prev_avg * 100
            trend = (
                "ìƒìŠ¹"
                if change_pct > 0.5
                else ("í•˜ë½" if change_pct < -0.5 else "ë³´í•©")
            )

            summary[col] = {
                "name": info["name"],
                "current": current_last,
                "avg": current_avg,
                "prev_avg": prev_avg,
                "change_pct": change_pct,
                "trend": trend,
                "unit": info["unit"],
                "format": info["format"],
            }
    return summary


# =============================================================================
# ë©”ì¸ ì•±
# =============================================================================


def main():
    df = load_data()

    if df is None or len(df) == 0:
        st.error(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {DATA_PATH}")
        return

    latest_date = df["ë‚ ì§œ"].max()
    today = datetime.now()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown("## âš™ï¸ ì„¤ì •")

        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", use_container_width=True):
            st.cache_data.clear()
            st.rerun()

        st.markdown("---")
        st.markdown("### ğŸ“‚ ì¹´í…Œê³ ë¦¬ í•„í„°")
        categories = list(INDICATORS.keys())
        selected_categories = st.multiselect(
            "í‘œì‹œí•  ì¹´í…Œê³ ë¦¬", categories, default=categories
        )

        st.markdown("---")
        st.markdown("### ğŸ“… ì°¨íŠ¸ ê¸°ê°„")
        selected_period = st.selectbox(
            "ê¸°ê°„ ì„ íƒ", list(CHART_PERIODS.keys()), index=2
        )

        st.markdown("---")
        st.markdown(
            f"""
        ### ğŸ“‹ ë°ì´í„° ì •ë³´
        - **ê¸°ì¤€ ë‚ ì§œ:** {latest_date.strftime('%Y-%m-%d')}
        - **ì´ ë°ì´í„°:** {len(df):,}í–‰
        - **ë²„ì „:** v7.0 (ì—‘ì…€+í¬ë¡¤ë§)
        """
        )

    # í—¤ë”
    st.markdown(
        f"""
    <div class="main-header">
        <h1>ğŸŒ± ì¹œí™˜ê²½Â·ì¸í”„ë¼ íˆ¬ì ëŒ€ì‹œë³´ë“œ v7.0</h1>
        <p>ğŸ“… ê¸°ì¤€ì¼: {latest_date.strftime('%Yë…„ %mì›” %dì¼')} | ğŸ—“ï¸ ì˜¤ëŠ˜: {today.strftime('%Yë…„ %mì›” %dì¼')} | ì¸í”„ë¼í”„ë¡ í‹°ì–´ìì‚°ìš´ìš©(ì£¼)</p>
    </div>
    """,
        unsafe_allow_html=True,
    )

    summary = get_summary(df)

    # ê¸‰ë³€ë™ ì•Œë¦¼
    alerts = check_alerts(summary)
    if alerts:
        st.markdown(
            f'<div class="alert-box"><h4>ğŸš¨ ê¸‰ë³€ë™ ì•Œë¦¼ ({len(alerts)}ê±´) - ê¸°ì¤€ì¼ ëŒ€ë¹„</h4></div>',
            unsafe_allow_html=True,
        )
        num_cols = 4
        num_rows = (len(alerts) + num_cols - 1) // num_cols
        for row in range(num_rows):
            cols = st.columns(num_cols)
            for col_idx in range(num_cols):
                alert_idx = row * num_cols + col_idx
                if alert_idx < len(alerts):
                    alert = alerts[alert_idx]
                    with cols[col_idx]:
                        direction = "â–²" if alert["direction"] == "up" else "â–¼"
                        color = "#00d26a" if alert["direction"] == "up" else "#ff6b6b"

                        prev_str = format_value(
                            alert.get("previous"),
                            alert.get("fmt", "{:,.2f}"),
                            alert.get("unit", ""),
                        )
                        curr_str = format_value(
                            alert.get("current"),
                            alert.get("fmt", "{:,.2f}"),
                            alert.get("unit", ""),
                        )

                        st.markdown(
                            f"""
                        <div class="alert-item" style="border-color: {color};">
                            <div style="color: #888; font-size: 0.8rem;">
                                {alert['icon']} {alert['category']}
                            </div>
                            <div style="color: #fff; font-weight: bold; margin-top: 2px;">
                                {alert['indicator']}
                            </div>
                            <div style="display:flex; justify-content:space-between; align-items:center; margin-top: 6px;">
                                <div style="color: {color}; font-weight: bold; font-size: 0.95rem;">
                                    {direction} {abs(alert['change_pct']):.2f}%
                                </div>
                                <div style="text-align: right; font-size: 0.75rem; line-height: 1.3;">
                                    <div style="color:#aaaaaa;">ì „ì¼: <span style="color:#ffffff;">{prev_str}</span></div>
                                    <div style="color:#aaaaaa;">í˜„ì¬: <span style="color:#ffffff;">{curr_str}</span></div>
                                </div>
                            </div>
                        </div>
                        """,
                            unsafe_allow_html=True,
                        )

    # íƒ­ êµ¬ì„±
    tab0, tab1, tab4, tab5, tab6, tab2, tab3 = st.tabs(
        [
            "ğŸ“– ì‚¬ìš© ë©”ë‰´ì–¼",
            "ğŸ“ˆ ì§€í‘œ í˜„í™©",
            "ğŸ”¬ ìƒê´€ê´€ê³„ ë¶„ì„",
            "ğŸ¯ ì˜ˆì¸¡ ë¶„ì„",
            "ğŸ“‹ ë°ì´í„°",
            "ğŸŒ± ì‹œë®¬ë ˆì´ì…˜",
            "ğŸ”” íˆ¬ì ì‹œê·¸ë„",
        ]
    )

    # TAB 0: ê°„ë‹¨ ë©”ë‰´ì–¼
    with tab0:
        st.markdown("## ğŸ“– ëŒ€ì‹œë³´ë“œ ì‚¬ìš© ë©”ë‰´ì–¼")
        st.markdown(
            """
        ì´ ëŒ€ì‹œë³´ë“œëŠ” **ì—‘ì…€ íˆìŠ¤í† ë¦¬ + ì›¹ í¬ë¡¤ë§(ë‹¹ì¼/ì „ì¼)** ë°ì´í„°ë¥¼ í•©ì³ì„œ  
        í™˜ìœ¨, REC, SMP, ìœ ê°€, LNG, ê¸ˆë¦¬, ìŠ¤ì™‘ ì§€í‘œë¥¼ í•œ ë²ˆì— ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•œ ë‚´ë¶€ìš© ë„êµ¬ì…ë‹ˆë‹¤.
        """
        )

        st.markdown("---")
        st.markdown("### 1ï¸âƒ£ ìƒë‹¨ ê¸‰ë³€ë™ ì•Œë¦¼")
        st.markdown(
            """
        - ì „ì¼ ëŒ€ë¹„ ë³€ë™ë¥ ì´ ì„ê³„ê°’ì„ ë„˜ëŠ” ì§€í‘œë§Œ í‘œì‹œí•©ë‹ˆë‹¤.  
        - ì˜ˆì‹œ  
          - í™˜ìœ¨: Â±1% ì´ìƒ  
          - REC: Â±3% ì´ìƒ  
          - SMP: Â±5% ì´ìƒ  
          - ê¸ˆë¦¬/ìŠ¤ì™‘: Â±10bp ì´ìƒ  
        - ì•„ì¹¨ íšŒì˜ì—ì„œ 'ë¬´ìŠ¨ ì§€í‘œê°€ í¬ê²Œ ì›€ì§ì˜€ëŠ”ì§€'ë§Œ ë¹ ë¥´ê²Œ í™•ì¸í•˜ëŠ” ìš©ë„ì…ë‹ˆë‹¤.
        """
        )

        st.markdown("---")
        st.markdown("### 2ï¸âƒ£ íƒ­ êµ¬ì¡° ìš”ì•½")
        st.markdown(
            """
        - **ğŸ“ˆ ì§€í‘œ í˜„í™©**: ì¹´í…Œê³ ë¦¬ë³„(í™˜ìœ¨/REC/SMP/ìœ ê°€/LNG/ê¸ˆë¦¬/ìŠ¤ì™‘) í˜„ì¬ê°’ & ì „ì¼ëŒ€ë¹„  
        - **ğŸ”¬ ìƒê´€ê´€ê³„ ë¶„ì„**: ë‘ ì§€í‘œ ê°„ ìƒê´€ê³„ìˆ˜, ì‹œì°¨(lag) ë¶„ì„  
        - **ğŸ¯ ì˜ˆì¸¡ ë¶„ì„**: íšŒê·€ëª¨í˜•ìœ¼ë¡œ SMP, ê¸ˆë¦¬ ë“±ì„ ë‹¤ë¥¸ ì§€í‘œë¡œ ì„¤ëª…/ì˜ˆì¸¡  
        - **ğŸŒ± ì‹œë®¬ë ˆì´ì…˜**: SMP/REC ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¥¸ ì‹ ì¬ìƒ ë°œì „ì†Œ ìˆ˜ìµì„± ê³„ì‚°  
        - **ğŸ”” íˆ¬ì ì‹œê·¸ë„**: ìµœê·¼ 30ì¼ í‰ê·  ëŒ€ë¹„ í˜„ì¬ ìœ„ì¹˜ ê¸°ë°˜ BUY/SELL/HOLD ìë™ ìƒì„±  
        - **ğŸ“‹ ë°ì´í„°**: ì›ë³¸ ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ ë° CSV ë‹¤ìš´ë¡œë“œ
        """
        )

        st.markdown("---")
        st.markdown("### 3ï¸âƒ£ ë°ì´í„° êµ¬ì¡°")
        st.markdown(
            """
        - ì—‘ì…€(`ë°ì¼ë¦¬_í´ë¦¬í•‘_ìë£Œ.xlsm`)ì— 2021ë…„ ì´í›„ íˆìŠ¤í† ë¦¬ê°€ ìˆê³ ,  
          ì˜¤ëŠ˜/ì „ì¼ ê°’ì€ **í¬ë¡¤ë§ ë°ì´í„°ë¡œ ë®ì–´ì¨ì„œ** ì‚¬ìš©í•©ë‹ˆë‹¤.  
        - ì—‘ì…€ì´ ì—†ë”ë¼ë„, í¬ë¡¤ë§ì´ ë˜ë©´ ìµœì†Œ 2í–‰(ì „ì¼/ë‹¹ì¼) ë°ì´í„°ë¡œ ëŒ€ì‹œë³´ë“œê°€ ë™ì‘í•©ë‹ˆë‹¤.
        """
        )

    # TAB 1: ì§€í‘œ í˜„í™©
    with tab1:
        st.markdown("### ğŸ“Š ì£¼ê°„ ì‹œì¥ íŠ¸ë Œë“œ")
        market_summary = generate_market_summary(df, days=7)

        if market_summary:
            cols = st.columns(5)
            for i, (col_name, data_m) in enumerate(market_summary.items()):
                with cols[i % 5]:
                    trend_color = (
                        "#00d26a"
                        if data_m["trend"] == "ìƒìŠ¹"
                        else ("#ff6b6b" if data_m["trend"] == "í•˜ë½" else "#888")
                    )
                    trend_arrow = (
                        "â†‘"
                        if data_m["trend"] == "ìƒìŠ¹"
                        else ("â†“" if data_m["trend"] == "í•˜ë½" else "â†’")
                    )
                    st.markdown(
                        f"""
                    <div class="summary-card">
                        <div style="color: #888; font-size: 0.8rem;">{data_m['name']}</div>
                        <div style="color: #fff; font-size: 1.3rem; font-weight: bold;">{data_m['format'].format(data_m['current'])} {data_m['unit']}</div>
                        <div style="color: {trend_color};">{trend_arrow} {data_m['trend']} ({data_m['change_pct']:+.1f}%)</div>
                    </div>
                    """,
                        unsafe_allow_html=True,
                    )

        st.markdown("---")

        for category in selected_categories:
            if category not in summary:
                continue
            data_c = summary[category]

            st.markdown(
                f"""
            <div class="category-header" style="border-color: {data_c['color']};">
                <span style="font-size: 1.5rem;">{data_c['icon']}</span>
                <h3>{category}</h3>
            </div>
            """,
                unsafe_allow_html=True,
            )

            cols = st.columns(4)
            is_rate = category in ["ê¸ˆë¦¬", "ìŠ¤ì™‘"]

            for i, (col_name, ind) in enumerate(data_c["indicators"].items()):
                with cols[i % 4]:
                    value_str = format_value(ind["value"], ind["format"], ind["unit"])
                    is_lng = ind.get("is_lng", False)
                    change_html = get_change_html(
                        ind["change"], ind["change_pct"], ind["direction"], is_rate, is_lng
                    )
                    note = ind.get("note", "")
                    st.markdown(
                        create_metric_card(col_name, value_str, change_html, note),
                        unsafe_allow_html=True,
                    )

    # TAB 2: ì‹œë®¬ë ˆì´ì…˜
    with tab2:
        st.markdown("## ğŸŒ± ì‹ ì¬ìƒì—ë„ˆì§€ ìˆ˜ìµì„± ì‹œë®¬ë ˆì´í„°")

        col1, col2 = st.columns([1, 2])

        with col1:
            st.markdown("### âš™ï¸ í”„ë¡œì íŠ¸ ì„¤ì •")

            project_type = st.selectbox(
                "ë°œì „ ìœ í˜•", ["íƒœì–‘ê´‘", "í’ë ¥(ìœ¡ìƒ)", "í’ë ¥(í•´ìƒ)", "ì—°ë£Œì „ì§€", "ë°”ì´ì˜¤"]
            )

            defaults = {
                "íƒœì–‘ê´‘": {"cf": 0.15, "rec_weight": 1.0},
                "í’ë ¥(ìœ¡ìƒ)": {"cf": 0.25, "rec_weight": 1.0},
                "í’ë ¥(í•´ìƒ)": {"cf": 0.30, "rec_weight": 2.0},
                "ì—°ë£Œì „ì§€": {"cf": 0.85, "rec_weight": 2.0},
                "ë°”ì´ì˜¤": {"cf": 0.80, "rec_weight": 1.5},
            }

            capacity = st.number_input(
                "ì„¤ë¹„ìš©ëŸ‰ (MW)", min_value=0.1, max_value=1000.0, value=10.0, step=0.1
            )
            cf = (
                st.slider(
                    "ì´ìš©ë¥  (%)", 5, 95, int(defaults[project_type]["cf"] * 100)
                )
                / 100
            )
            rec_weight = st.number_input(
                "REC ê°€ì¤‘ì¹˜",
                min_value=0.5,
                max_value=5.0,
                value=defaults[project_type]["rec_weight"],
                step=0.1,
            )

            st.markdown("### ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •")

            current_smp = (
                df["ìœ¡ì§€ SMP"].dropna().iloc[-1]
                if "ìœ¡ì§€ SMP" in df.columns and len(df["ìœ¡ì§€ SMP"].dropna()) > 0
                else 100
            )
            current_rec = (
                df["ìœ¡ì§€ ê°€ê²©"].dropna().iloc[-1]
                if "ìœ¡ì§€ ê°€ê²©" in df.columns and len(df["ìœ¡ì§€ ê°€ê²©"].dropna()) > 0
                else 70000
            )

            smp_scenarios = st.multiselect(
                "SMP ì‹œë‚˜ë¦¬ì˜¤ (ì›/kWh)",
                [80, 100, 120, 150, 180, 200, 220],
                default=[100, 150, 200],
            )
            rec_scenario = st.number_input(
                "REC ê°€ê²© (ì›/REC)",
                min_value=10000,
                max_value=200000,
                value=int(current_rec),
                step=1000,
            )

        with col2:
            st.markdown("### ğŸ“ˆ ìˆ˜ìµ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")

            if smp_scenarios:
                results = []
                for smp in smp_scenarios:
                    rev = calculate_renewable_revenue(
                        smp, rec_scenario, capacity, cf, rec_weight
                    )
                    results.append(
                        {
                            "SMP (ì›/kWh)": smp,
                            "ì—°ê°„ë°œì „ëŸ‰ (MWh)": f"{rev['annual_generation_mwh']:,.0f}",
                            "SMP ìˆ˜ìµ (ì–µì›)": f"{rev['smp_revenue']/100000000:.2f}",
                            "REC ìˆ˜ìµ (ì–µì›)": f"{rev['rec_revenue']/100000000:.2f}",
                            "ì´ ìˆ˜ìµ (ì–µì›)": f"{rev['total_revenue']/100000000:.2f}",
                        }
                    )

                st.dataframe(
                    pd.DataFrame(results), use_container_width=True, hide_index=True
                )

                fig = go.Figure()
                revenues = [
                    calculate_renewable_revenue(
                        smp, rec_scenario, capacity, cf, rec_weight
                    )["total_revenue"]
                    / 100000000
                    for smp in smp_scenarios
                ]
                fig.add_trace(
                    go.Bar(
                        x=[f"SMP {s}" for s in smp_scenarios],
                        y=revenues,
                        marker_color="#27ae60",
                        text=[f"{r:.1f}ì–µ" for r in revenues],
                        textposition="outside",
                    )
                )
                fig.update_layout(
                    title=f"{project_type} {capacity}MW ì—°ê°„ ì˜ˆìƒ ìˆ˜ìµ",
                    yaxis_title="ì´ ìˆ˜ìµ (ì–µì›)",
                    template="plotly_dark",
                    paper_bgcolor="rgba(22,33,62,0.8)",
                    plot_bgcolor="rgba(22,33,62,0.8)",
                    height=350,
                )
                st.plotly_chart(fig, use_container_width=True)

    # TAB 3: íˆ¬ì ì‹œê·¸ë„
    with tab3:
        st.markdown("## ğŸ”” íˆ¬ì ì˜ì‚¬ê²°ì • ì‹œê·¸ë„")
        st.markdown("ìµœê·¼ 30ì¼ í‰ê·  ëŒ€ë¹„ í˜„ì¬ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹ í˜¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

        signals = generate_investment_signals(df, days=30)

        if signals:
            for signal in signals:
                if signal["signal"] == "BUY":
                    css_class, icon, label = "signal-buy", "ğŸŸ¢", "ë§¤ìˆ˜ ì ê¸°"
                elif signal["signal"] == "SELL":
                    css_class, icon, label = "signal-sell", "ğŸ”´", "ë§¤ë„ ê³ ë ¤"
                else:
                    css_class, icon, label = "signal-hold", "ğŸŸ¡", "ê´€ë§"

                st.markdown(
                    f"""
                <div class="{css_class}">
                    <div style="font-size: 2rem;">{icon}</div>
                    <div style="color: #fff; font-size: 1.2rem; font-weight: bold;">{signal['category']} - {signal['indicator']}</div>
                    <div style="color: #fff; font-size: 1.5rem; font-weight: bold;">{label}</div>
                    <div style="color: #aaa; margin-top: 0.5rem;">{signal['reason']}</div>
                    <div style="color: #888; font-size: 0.8rem;">ì‹ í˜¸ ê°•ë„: {signal['strength']}</div>
                </div>
                """,
                    unsafe_allow_html=True,
                )
                st.markdown("<br>", unsafe_allow_html=True)
        else:
            st.info("í˜„ì¬ íŠ¹ë³„í•œ íˆ¬ì ì‹œê·¸ë„ì´ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        st.markdown("### ğŸ“‹ ì¢…í•© ì‹œì¥ ë¶„ì„")

        latest_row = df.iloc[-1]
        analysis_points = []

        smp_current = latest_row.get("ìœ¡ì§€ SMP")
        smp_avg_90d = df.tail(90)["ìœ¡ì§€ SMP"].mean()
        if pd.notna(smp_current) and pd.notna(smp_avg_90d):
            smp_vs_avg = (smp_current / smp_avg_90d - 1) * 100
            if smp_vs_avg > 10:
                analysis_points.append(
                    f"âš¡ SMPê°€ 90ì¼ í‰ê·  ëŒ€ë¹„ **{smp_vs_avg:.1f}% ë†’ìŒ** - ì‹ ì¬ìƒ ë°œì „ ìˆ˜ìµì„± ì–‘í˜¸"
                )
            elif smp_vs_avg < -10:
                analysis_points.append(
                    f"âš¡ SMPê°€ 90ì¼ í‰ê·  ëŒ€ë¹„ **{abs(smp_vs_avg):.1f}% ë‚®ìŒ** - ìˆ˜ìµì„± ì£¼ì˜"
                )

        rate_current = latest_row.get("êµ­ê³ ì±„ (3ë…„)")
        rate_avg_90d = df.tail(90)["êµ­ê³ ì±„ (3ë…„)"].mean()
        if pd.notna(rate_current) and pd.notna(rate_avg_90d):
            if rate_current > rate_avg_90d + 0.2:
                analysis_points.append(
                    f"ğŸ“Š ê¸ˆë¦¬ ìƒìŠ¹ ì¶”ì„¸ ({rate_current:.2f}%) - PF ì¡°ë‹¬ë¹„ìš© ìƒìŠ¹ ì˜ˆìƒ"
                )
            elif rate_current < rate_avg_90d - 0.2:
                analysis_points.append(
                    f"ğŸ“Š ê¸ˆë¦¬ í•˜ë½ ì¶”ì„¸ ({rate_current:.2f}%) - ë¦¬íŒŒì´ë‚¸ì‹± ì ê¸°"
                )

        if analysis_points:
            for point in analysis_points:
                st.markdown(f"- {point}")
        else:
            st.info("ì‹œì¥ì´ ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì…ë‹ˆë‹¤.")

    # TAB 4: ìƒê´€ê´€ê³„ ë¶„ì„
    with tab4:
        st.markdown("## ğŸ”¬ ì„ í–‰/í›„í–‰ ì§€í‘œ ìƒê´€ê´€ê³„ ë¶„ì„")

        col1, col2 = st.columns([1, 3])

        with col1:
            heatmap_period = st.selectbox(
                "ë¶„ì„ ê¸°ê°„", ["3ê°œì›”", "6ê°œì›”", "1ë…„", "ì „ì²´"], index=2, key="hm_p"
            )
            heatmap_indicators = st.multiselect(
                "ë¶„ì„ ì§€í‘œ",
                KEY_INDICATORS,
                default=["ë‹¬ëŸ¬í™˜ìœ¨", "ìœ¡ì§€ SMP", "ë‘ë°”ì´ìœ ", "êµ­ê³ ì±„ (3ë…„)"],
                key="hm_i",
            )

        with col2:
            if len(heatmap_indicators) >= 2:
                days = CHART_PERIODS.get(heatmap_period)
                corr_matrix = calculate_correlation_matrix(
                    df, heatmap_indicators, days
                )

                fig = px.imshow(
                    corr_matrix,
                    labels=dict(color="ìƒê´€ê³„ìˆ˜"),
                    x=heatmap_indicators,
                    y=heatmap_indicators,
                    color_continuous_scale="RdBu_r",
                    zmin=-1,
                    zmax=1,
                    text_auto=".2f",
                )
                fig.update_layout(
                    template="plotly_dark",
                    paper_bgcolor="rgba(22,33,62,0.8)",
                    plot_bgcolor="rgba(22,33,62,0.8)",
                    height=400,
                )
                st.plotly_chart(fig, use_container_width=True)

        st.markdown("---")
        st.markdown("### ğŸ• ì‹œì°¨(Lag) ë¶„ì„")

        col1, col2, col3 = st.columns(3)
        with col1:
            leading = st.selectbox(
                "ì„ í–‰ì§€í‘œ", KEY_INDICATORS, index=5, key="ld"
            )
        with col2:
            lagging = st.selectbox(
                "í›„í–‰ì§€í‘œ", KEY_INDICATORS, index=3, key="lg"
            )
        with col3:
            max_lag = st.slider("ìµœëŒ€ ì‹œì°¨", 1, 365, 180, key="ml")

        if leading != lagging:
            lag_df = calculate_lagged_correlation(
                df, leading, lagging, max_lag
            )
            optimal = find_optimal_lag(lag_df)

            fig = go.Figure()
            fig.add_trace(
                go.Scatter(
                    x=lag_df["lag"],
                    y=lag_df["correlation"],
                    mode="lines+markers",
                    line=dict(color="#3498db"),
                )
            )
            if optimal is not None:
                fig.add_vline(x=optimal["lag"], line_dash="dash", line_color="#e94560")
            fig.add_hline(y=0, line_dash="dot", line_color="gray")
            fig.update_layout(
                title=f"{leading} â†’ {lagging}",
                template="plotly_dark",
                paper_bgcolor="rgba(22,33,62,0.8)",
                plot_bgcolor="rgba(22,33,62,0.8)",
                height=300,
                yaxis=dict(range=[-1, 1]),
            )
            st.plotly_chart(fig, use_container_width=True)

            if optimal is not None and not np.isnan(optimal["correlation"]):
                strength, direction, _ = interpret_correlation(
                    optimal["correlation"]
                )
                st.info(
                    f"ğŸ“Œ ìµœì  ì‹œì°¨: **{int(optimal['lag'])}ì¼** | ìƒê´€ê³„ìˆ˜: **{optimal['correlation']:.3f}** ({strength} {direction} ìƒê´€ê´€ê³„)"
                )

    # TAB 5: ì˜ˆì¸¡ ë¶„ì„
    with tab5:
        st.markdown("## ğŸ¯ íšŒê·€ë¶„ì„ ê¸°ë°˜ ì˜ˆì¸¡")

        col1, col2 = st.columns([1, 2])

        with col1:
            target = st.selectbox(
                "ì˜ˆì¸¡ ëŒ€ìƒ", KEY_INDICATORS, index=3, key="pt"
            )

            feature_options = [x for x in KEY_INDICATORS if x != target]

            base_default = ["ë‘ë°”ì´ìœ ", "ë‹¬ëŸ¬í™˜ìœ¨"]
            default_features = [
                x for x in base_default if x in feature_options
            ]

            features = st.multiselect(
                "ì„¤ëª… ë³€ìˆ˜",
                feature_options,
                default=default_features,
                key="pf",
            )

            train_period = st.selectbox(
                "í•™ìŠµ ê¸°ê°„", ["3ê°œì›”", "6ê°œì›”", "1ë…„", "ì „ì²´"], index=2, key="tp"
            )
            run_pred = st.button("ğŸš€ ì˜ˆì¸¡ ì‹¤í–‰", use_container_width=True)

        with col2:
            if run_pred and features:
                train_days = CHART_PERIODS.get(train_period)
                model_info, _, _, error = build_regression_model(
                    df, target, features, train_days
                )

                if error:
                    st.error(error)
                elif model_info:
                    st.markdown(
                        f"**RÂ² (ì„¤ëª…ë ¥): {model_info['r2']:.3f}** | MAE: {model_info['mae']:.2f}"
                    )

                    fig = go.Figure()
                    fig.add_trace(
                        go.Scatter(
                            x=model_info["dates"],
                            y=model_info["y_actual"],
                            mode="lines",
                            name="ì‹¤ì œê°’",
                            line=dict(color="#3498db"),
                        )
                    )
                    fig.add_trace(
                        go.Scatter(
                            x=model_info["dates"],
                            y=model_info["y_pred"],
                            mode="lines",
                            name="ì˜ˆì¸¡ê°’",
                            line=dict(color="#e94560", dash="dot"),
                        )
                    )
                    fig.update_layout(
                        template="plotly_dark",
                        paper_bgcolor="rgba(22,33,62,0.8)",
                        plot_bgcolor="rgba(22,33,62,0.8)",
                        height=300,
                    )
                    st.plotly_chart(fig, use_container_width=True)

                    pred = predict_future(model_info, df, features)
                    actual = df[target].dropna().iloc[-1]
                    st.success(
                        f"**í˜„ì¬ ì˜ˆì¸¡ê°’: {pred:.2f}** (ì‹¤ì œ: {actual:.2f})"
                    )
            elif run_pred:
                st.warning("ì„¤ëª… ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

    # TAB 6: ë°ì´í„°
    with tab6:
        st.markdown("### ğŸ“‹ ì›ë³¸ ë°ì´í„°")

        col1, col2 = st.columns(2)
        with col1:
            date_range = st.date_input(
                "ë‚ ì§œ ë²”ìœ„",
                value=(latest_date - timedelta(days=30), latest_date),
            )
        with col2:
            table_cat = st.selectbox(
                "ì¹´í…Œê³ ë¦¬", ["ì „ì²´"] + list(INDICATORS.keys()), key="tc"
            )

        df_table = df.copy()
        if isinstance(date_range, (list, tuple)) and len(date_range) == 2:
            start, end = date_range
            df_table = df_table[
                (df_table["ë‚ ì§œ"] >= pd.to_datetime(start))
                & (df_table["ë‚ ì§œ"] <= pd.to_datetime(end))
            ]

        if table_cat != "ì „ì²´":
            cols = ["ë‚ ì§œ"] + list(INDICATORS[table_cat]["columns"].keys())
            existing = [c for c in cols if c in df_table.columns]
            df_table = df_table[existing]

        df_display = df_table.copy()
        df_display["ë‚ ì§œ"] = df_display["ë‚ ì§œ"].dt.strftime("%Y-%m-%d")
        st.dataframe(
            df_display.sort_values("ë‚ ì§œ", ascending=False),
            use_container_width=True,
            height=400,
        )

        csv = df_display.to_csv(index=False, encoding="utf-8-sig")
        st.download_button(
            "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
            csv,
            f"data_{datetime.now().strftime('%Y%m%d')}.csv",
            "text/csv",
        )

    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        """
    <div style="text-align: center; color: #666; padding: 1rem;">
        ğŸŒ± ì¹œí™˜ê²½Â·ì¸í”„ë¼ íˆ¬ì ëŒ€ì‹œë³´ë“œ v7.0 | ì‹ ì¬ìƒì—ë„ˆì§€Â·ìˆœí™˜ê²½ì œÂ·ê¸ˆìœµ ì§€í‘œ ëŒ€ì‹œë³´ë“œ (ì—‘ì…€+í¬ë¡¤ë§ í†µí•©)
    </div>
    """,
        unsafe_allow_html=True,
    )


if __name__ == "__main__":
    main()
